{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d22e9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d844aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('gas_turbines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d84b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a412630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      False\n",
       "AP      False\n",
       "AH      False\n",
       "AFDP    False\n",
       "GTEP    False\n",
       "TIT     False\n",
       "TAT     False\n",
       "TEY     False\n",
       "CDP     False\n",
       "CO      False\n",
       "NOX     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c790768b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      0\n",
       "AP      0\n",
       "AH      0\n",
       "AFDP    0\n",
       "GTEP    0\n",
       "TIT     0\n",
       "TAT     0\n",
       "TEY     0\n",
       "CDP     0\n",
       "CO      0\n",
       "NOX     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd52ea67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      float64\n",
       "AP      float64\n",
       "AH      float64\n",
       "AFDP    float64\n",
       "GTEP    float64\n",
       "TIT     float64\n",
       "TAT     float64\n",
       "TEY     float64\n",
       "CDP     float64\n",
       "CO      float64\n",
       "NOX     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a50189b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      12086\n",
       "AP        540\n",
       "AH      12637\n",
       "AFDP    11314\n",
       "GTEP     8234\n",
       "TIT       706\n",
       "TAT      2340\n",
       "TEY      4207\n",
       "CDP      3611\n",
       "CO      13096\n",
       "NOX     11996\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7184cbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60b773aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52f96fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AT</th>\n",
       "      <td>15039.0</td>\n",
       "      <td>17.764381</td>\n",
       "      <td>7.574323</td>\n",
       "      <td>0.522300</td>\n",
       "      <td>11.408000</td>\n",
       "      <td>18.1860</td>\n",
       "      <td>23.8625</td>\n",
       "      <td>34.9290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>15039.0</td>\n",
       "      <td>1013.199240</td>\n",
       "      <td>6.410760</td>\n",
       "      <td>985.850000</td>\n",
       "      <td>1008.900000</td>\n",
       "      <td>1012.8000</td>\n",
       "      <td>1016.9000</td>\n",
       "      <td>1034.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AH</th>\n",
       "      <td>15039.0</td>\n",
       "      <td>79.124174</td>\n",
       "      <td>13.793439</td>\n",
       "      <td>30.344000</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>82.2660</td>\n",
       "      <td>90.0435</td>\n",
       "      <td>100.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFDP</th>\n",
       "      <td>15039.0</td>\n",
       "      <td>4.200294</td>\n",
       "      <td>0.760197</td>\n",
       "      <td>2.087400</td>\n",
       "      <td>3.723900</td>\n",
       "      <td>4.1862</td>\n",
       "      <td>4.5509</td>\n",
       "      <td>7.6106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEP</th>\n",
       "      <td>15039.0</td>\n",
       "      <td>25.419061</td>\n",
       "      <td>4.173916</td>\n",
       "      <td>17.878000</td>\n",
       "      <td>23.294000</td>\n",
       "      <td>25.0820</td>\n",
       "      <td>27.1840</td>\n",
       "      <td>37.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIT</th>\n",
       "      <td>15039.0</td>\n",
       "      <td>1083.798770</td>\n",
       "      <td>16.527806</td>\n",
       "      <td>1000.800000</td>\n",
       "      <td>1079.600000</td>\n",
       "      <td>1088.7000</td>\n",
       "      <td>1096.0000</td>\n",
       "      <td>1100.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAT</th>\n",
       "      <td>15039.0</td>\n",
       "      <td>545.396183</td>\n",
       "      <td>7.866803</td>\n",
       "      <td>512.450000</td>\n",
       "      <td>542.170000</td>\n",
       "      <td>549.8900</td>\n",
       "      <td>550.0600</td>\n",
       "      <td>550.6100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEY</th>\n",
       "      <td>15039.0</td>\n",
       "      <td>134.188464</td>\n",
       "      <td>15.829717</td>\n",
       "      <td>100.170000</td>\n",
       "      <td>127.985000</td>\n",
       "      <td>133.7800</td>\n",
       "      <td>140.8950</td>\n",
       "      <td>174.6100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDP</th>\n",
       "      <td>15039.0</td>\n",
       "      <td>12.102353</td>\n",
       "      <td>1.103196</td>\n",
       "      <td>9.904400</td>\n",
       "      <td>11.622000</td>\n",
       "      <td>12.0250</td>\n",
       "      <td>12.5780</td>\n",
       "      <td>15.0810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>15039.0</td>\n",
       "      <td>1.972499</td>\n",
       "      <td>2.222206</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.858055</td>\n",
       "      <td>1.3902</td>\n",
       "      <td>2.1604</td>\n",
       "      <td>44.1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>15039.0</td>\n",
       "      <td>68.190934</td>\n",
       "      <td>10.470586</td>\n",
       "      <td>27.765000</td>\n",
       "      <td>61.303500</td>\n",
       "      <td>66.6010</td>\n",
       "      <td>73.9355</td>\n",
       "      <td>119.8900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count         mean        std          min          25%        50%  \\\n",
       "AT    15039.0    17.764381   7.574323     0.522300    11.408000    18.1860   \n",
       "AP    15039.0  1013.199240   6.410760   985.850000  1008.900000  1012.8000   \n",
       "AH    15039.0    79.124174  13.793439    30.344000    69.750000    82.2660   \n",
       "AFDP  15039.0     4.200294   0.760197     2.087400     3.723900     4.1862   \n",
       "GTEP  15039.0    25.419061   4.173916    17.878000    23.294000    25.0820   \n",
       "TIT   15039.0  1083.798770  16.527806  1000.800000  1079.600000  1088.7000   \n",
       "TAT   15039.0   545.396183   7.866803   512.450000   542.170000   549.8900   \n",
       "TEY   15039.0   134.188464  15.829717   100.170000   127.985000   133.7800   \n",
       "CDP   15039.0    12.102353   1.103196     9.904400    11.622000    12.0250   \n",
       "CO    15039.0     1.972499   2.222206     0.000388     0.858055     1.3902   \n",
       "NOX   15039.0    68.190934  10.470586    27.765000    61.303500    66.6010   \n",
       "\n",
       "            75%        max  \n",
       "AT      23.8625    34.9290  \n",
       "AP    1016.9000  1034.2000  \n",
       "AH      90.0435   100.2000  \n",
       "AFDP     4.5509     7.6106  \n",
       "GTEP    27.1840    37.4020  \n",
       "TIT   1096.0000  1100.8000  \n",
       "TAT    550.0600   550.6100  \n",
       "TEY    140.8950   174.6100  \n",
       "CDP     12.5780    15.0810  \n",
       "CO       2.1604    44.1030  \n",
       "NOX     73.9355   119.8900  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c5a52ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEY     1.000000\n",
       "CDP     0.988473\n",
       "GTEP    0.977042\n",
       "TIT     0.891587\n",
       "AFDP    0.717995\n",
       "AP      0.146939\n",
       "NOX    -0.102631\n",
       "AH     -0.110272\n",
       "AT     -0.207495\n",
       "CO     -0.541751\n",
       "TAT    -0.720356\n",
       "Name: TEY, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()[\"TEY\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72033eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AT', 'AP', 'AH', 'AFDP', 'GTEP', 'TIT', 'TAT', 'TEY', 'CDP', 'CO',\n",
       "       'NOX'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features = df.describe(include=[\"int64\",\"float64\"]).columns\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82dcd5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " plt.figure(figsize=(20,16))\n",
    "sns.boxplot(data=df[numerical_features], orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad91bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model =Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=100,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_absolute_error',\n",
    "        metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3c95fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\91720\\anaconda3\\lib\\site-packages (from keras-tuner) (1.21.5)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\91720\\anaconda3\\lib\\site-packages (from keras-tuner) (2.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\91720\\anaconda3\\lib\\site-packages (from keras-tuner) (2.27.1)\n",
      "Requirement already satisfied: ipython in c:\\users\\91720\\anaconda3\\lib\\site-packages (from keras-tuner) (8.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\91720\\anaconda3\\lib\\site-packages (from keras-tuner) (21.3)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\91720\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.1.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\91720\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.7.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\91720\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\91720\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (5.1.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (61.2.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\91720\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.18.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\91720\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (2.11.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (3.0.20)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->keras-tuner) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\91720\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from packaging->keras-tuner) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.3)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\91720\\anaconda3\\lib\\site-packages (from stack-data->ipython->keras-tuner) (0.2.2)\n",
      "Requirement already satisfied: asttokens in c:\\users\\91720\\anaconda3\\lib\\site-packages (from stack-data->ipython->keras-tuner) (2.0.5)\n",
      "Requirement already satisfied: executing in c:\\users\\91720\\anaconda3\\lib\\site-packages (from stack-data->ipython->keras-tuner) (0.8.3)\n",
      "Requirement already satisfied: six in c:\\users\\91720\\anaconda3\\lib\\site-packages (from asttokens->stack-data->ipython->keras-tuner) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.2.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.42.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (3.3.4)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.33.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (3.19.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\91720\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.1.3 kt-legacy-1.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d0e73bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91720\\AppData\\Local\\Temp\\ipykernel_16772\\2610907151.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60a2c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.optimizers import Adam\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.constraints import maxnorm\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8eaeab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(build_model,objective='val_mean_absolute_error',max_trials=5,  executions_per_trial=3,directory='project',project_name='Gas Turbine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e84c24b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 100, 'step': 32, 'sampling': None}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 100, 'step': 32, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c053b4bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in project\\Gas Turbine\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000021B7AD9F0A0>\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35e65c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(32,input_dim=7,activation='relu'))\n",
    "    model1.add(Dense(64,activation='relu'))\n",
    "    model1.add(Dense(96,activation=\"relu\"))\n",
    "    model1.add(Dense(32,activation=\"relu\"))\n",
    "    model1.add(Dense(64,activation=\"relu\"))\n",
    "    model1.add(Dense(32,activation=\"relu\"))\n",
    "    model1.add(Dense(96,activation=\"relu\"))\n",
    "    model1.add(Dense(96,activation=\"relu\"))\n",
    "    model1.add(Dense(32,activation=\"relu\"))\n",
    "    model1.add(Dense(64,activation=\"relu\"))\n",
    "    model1.add(Dense(64,activation=\"relu\"))\n",
    "    model1.add(Dense(units=1,activation=\"linear\"))\n",
    "    \n",
    "    adam=Adam(learning_rate=0.001)\n",
    "    model1.compile(loss='mean_absolute_error',optimizer = adam,metrics=[\"mean_absolute_error\"])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b3c4e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 =KerasRegressor(build_fn=create_model,verbose=0)\n",
    "batch_size=[10,20,40,50]\n",
    "epochs=[10,50,100,200]\n",
    "param_grid=dict(batch_size=batch_size,epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model1,param_grid=param_grid,cv=KFold(),verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba23ffcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5; 1/16] START batch_size=10, epochs=10...................................\n",
      "[CV 1/5; 1/16] END ...batch_size=10, epochs=10;, score=-2.854 total time=   5.3s\n",
      "[CV 2/5; 1/16] START batch_size=10, epochs=10...................................\n",
      "[CV 2/5; 1/16] END ...batch_size=10, epochs=10;, score=-1.303 total time=   4.9s\n",
      "[CV 3/5; 1/16] START batch_size=10, epochs=10...................................\n",
      "[CV 3/5; 1/16] END ...batch_size=10, epochs=10;, score=-2.746 total time=   4.7s\n",
      "[CV 4/5; 1/16] START batch_size=10, epochs=10...................................\n",
      "[CV 4/5; 1/16] END ...batch_size=10, epochs=10;, score=-2.759 total time=   4.6s\n",
      "[CV 5/5; 1/16] START batch_size=10, epochs=10...................................\n",
      "[CV 5/5; 1/16] END ...batch_size=10, epochs=10;, score=-2.580 total time=   4.6s\n",
      "[CV 1/5; 2/16] START batch_size=10, epochs=50...................................\n",
      "[CV 1/5; 2/16] END ...batch_size=10, epochs=50;, score=-0.785 total time=  17.9s\n",
      "[CV 2/5; 2/16] START batch_size=10, epochs=50...................................\n",
      "[CV 2/5; 2/16] END ...batch_size=10, epochs=50;, score=-0.814 total time=  19.9s\n",
      "[CV 3/5; 2/16] START batch_size=10, epochs=50...................................\n",
      "[CV 3/5; 2/16] END ...batch_size=10, epochs=50;, score=-4.750 total time=  21.3s\n",
      "[CV 4/5; 2/16] START batch_size=10, epochs=50...................................\n",
      "[CV 4/5; 2/16] END ...batch_size=10, epochs=50;, score=-0.950 total time=  20.6s\n",
      "[CV 5/5; 2/16] START batch_size=10, epochs=50...................................\n",
      "[CV 5/5; 2/16] END ...batch_size=10, epochs=50;, score=-1.262 total time=  19.2s\n",
      "[CV 1/5; 3/16] START batch_size=10, epochs=100..................................\n",
      "[CV 1/5; 3/16] END ..batch_size=10, epochs=100;, score=-1.943 total time=  42.4s\n",
      "[CV 2/5; 3/16] START batch_size=10, epochs=100..................................\n",
      "[CV 2/5; 3/16] END ..batch_size=10, epochs=100;, score=-2.031 total time=  45.5s\n",
      "[CV 3/5; 3/16] START batch_size=10, epochs=100..................................\n",
      "[CV 3/5; 3/16] END ..batch_size=10, epochs=100;, score=-1.148 total time=  52.4s\n",
      "[CV 4/5; 3/16] START batch_size=10, epochs=100..................................\n",
      "[CV 4/5; 3/16] END ..batch_size=10, epochs=100;, score=-1.574 total time=  59.8s\n",
      "[CV 5/5; 3/16] START batch_size=10, epochs=100..................................\n",
      "[CV 5/5; 3/16] END ..batch_size=10, epochs=100;, score=-0.833 total time=  53.2s\n",
      "[CV 1/5; 4/16] START batch_size=10, epochs=200..................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:164\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m fit_args \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_sk_params(Sequential\u001b[38;5;241m.\u001b[39mfit))\n\u001b[0;32m    162\u001b[0m fit_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> 164\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba5e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "params = grid_result.cv_results_[\"params\"]\n",
    "for mean,stdev,param in zip(means,stds,params):\n",
    "    print(\"{},{} with {}\".format(mean,stdev,param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "635a7dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>AT</th>\n",
       "      <th>TEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.605</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>6.8594</td>\n",
       "      <td>114.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.598</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>6.7850</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.601</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>6.8977</td>\n",
       "      <td>114.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.606</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>7.0569</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.612</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>7.3978</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CDP    GTEP     TIT     TAT    AFDP      CO      AT     TEY\n",
       "0  10.605  19.663  1059.2  550.00  3.5000  3.1547  6.8594  114.70\n",
       "1  10.598  19.728  1059.3  550.00  3.4998  3.2363  6.7850  114.72\n",
       "2  10.601  19.779  1059.4  549.87  3.4824  3.2012  6.8977  114.71\n",
       "3  10.606  19.792  1059.6  549.99  3.4805  3.1923  7.0569  114.72\n",
       "4  10.612  19.765  1059.7  549.98  3.4976  3.2484  7.3978  114.72"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = df[['CDP', 'GTEP','TIT', 'TAT', 'AFDP', 'CO', 'AT',\"TEY\"]]\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f7c0fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>AT</th>\n",
       "      <th>TEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.605</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>6.8594</td>\n",
       "      <td>114.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.598</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>6.7850</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.601</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>6.8977</td>\n",
       "      <td>114.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.606</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>7.0569</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.612</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>7.3978</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>10.400</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>9.0301</td>\n",
       "      <td>111.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>10.433</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>7.8879</td>\n",
       "      <td>111.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>10.483</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>7.2647</td>\n",
       "      <td>110.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>10.533</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>7.0060</td>\n",
       "      <td>110.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>10.583</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>6.9279</td>\n",
       "      <td>111.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CDP    GTEP     TIT     TAT    AFDP      CO      AT     TEY\n",
       "0      10.605  19.663  1059.2  550.00  3.5000  3.1547  6.8594  114.70\n",
       "1      10.598  19.728  1059.3  550.00  3.4998  3.2363  6.7850  114.72\n",
       "2      10.601  19.779  1059.4  549.87  3.4824  3.2012  6.8977  114.71\n",
       "3      10.606  19.792  1059.6  549.99  3.4805  3.1923  7.0569  114.72\n",
       "4      10.612  19.765  1059.7  549.98  3.4976  3.2484  7.3978  114.72\n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...\n",
       "15034  10.400  19.164  1049.7  546.21  3.5421  4.5186  9.0301  111.61\n",
       "15035  10.433  19.414  1046.3  543.22  3.5059  4.8470  7.8879  111.78\n",
       "15036  10.483  19.530  1037.7  537.32  3.4770  7.9632  7.2647  110.19\n",
       "15037  10.533  19.377  1043.2  541.24  3.4486  6.2494  7.0060  110.74\n",
       "15038  10.583  19.306  1049.9  545.85  3.4275  4.9816  6.9279  111.58\n",
       "\n",
       "[15039 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51789053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "256a2ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12031, 7)\n",
      "(3008, 7)\n",
      "(12031, 1)\n",
      "(3008, 1)\n"
     ]
    }
   ],
   "source": [
    "x = model_data.drop('TEY', axis=1)\n",
    "y = model_data[[\"TEY\"]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.20, random_state=42)\n",
    "\n",
    "scaler_train = StandardScaler()\n",
    "scaler_test = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler_train.fit_transform(x_train) \n",
    "x_test_scaled  = scaler_test.fit_transform(x_test) \n",
    "\n",
    "print(x_train_scaled.shape)\n",
    "print(x_test_scaled.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d621bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 17632.9609 - mae: 131.8193 - mse: 17632.9609 - val_loss: 16784.5039 - val_mae: 128.5937 - val_mse: 16784.5039\n",
      "Epoch 2/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 16286.7461 - mae: 126.6246 - mse: 16286.7461 - val_loss: 15729.5830 - val_mae: 124.4249 - val_mse: 15729.5830\n",
      "Epoch 3/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 15310.7959 - mae: 122.7104 - mse: 15310.7959 - val_loss: 14811.2422 - val_mae: 120.6782 - val_mse: 14811.2422\n",
      "Epoch 4/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 14426.1611 - mae: 119.0548 - mse: 14426.1611 - val_loss: 13958.8633 - val_mae: 117.0935 - val_mse: 13958.8633\n",
      "Epoch 5/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 13597.5146 - mae: 115.5213 - mse: 13597.5146 - val_loss: 13154.8955 - val_mae: 113.6086 - val_mse: 13154.8955\n",
      "Epoch 6/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 12813.0762 - mae: 112.0704 - mse: 12813.0762 - val_loss: 12391.3682 - val_mae: 110.1971 - val_mse: 12391.3682\n",
      "Epoch 7/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 12066.9170 - mae: 108.6953 - mse: 12066.9170 - val_loss: 11664.3350 - val_mae: 106.8474 - val_mse: 11664.3350\n",
      "Epoch 8/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 11355.6270 - mae: 105.3700 - mse: 11355.6270 - val_loss: 10970.5713 - val_mae: 103.5500 - val_mse: 10970.5713\n",
      "Epoch 9/100\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 10676.3008 - mae: 102.0980 - mse: 10676.3008 - val_loss: 10307.8926 - val_mae: 100.2992 - val_mse: 10307.8926\n",
      "Epoch 10/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 10027.2119 - mae: 98.8703 - mse: 10027.2119 - val_loss: 9674.4277 - val_mae: 97.0899 - val_mse: 9674.4277\n",
      "Epoch 11/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 9406.9004 - mae: 95.6826 - mse: 9406.9004 - val_loss: 9069.5273 - val_mae: 93.9231 - val_mse: 9069.5273\n",
      "Epoch 12/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 8814.1436 - mae: 92.5303 - mse: 8814.1445 - val_loss: 8490.9229 - val_mae: 90.7907 - val_mse: 8490.9229\n",
      "Epoch 13/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 8247.7568 - mae: 89.4174 - mse: 8247.7568 - val_loss: 7938.7046 - val_mae: 87.6968 - val_mse: 7938.7046\n",
      "Epoch 14/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 7706.8794 - mae: 86.3377 - mse: 7706.8789 - val_loss: 7411.0747 - val_mae: 84.6351 - val_mse: 7411.0747\n",
      "Epoch 15/100\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 7190.4893 - mae: 83.2934 - mse: 7190.4893 - val_loss: 6908.0605 - val_mae: 81.6094 - val_mse: 6908.0605\n",
      "Epoch 16/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 6697.9639 - mae: 80.2834 - mse: 6697.9639 - val_loss: 6428.4395 - val_mae: 78.6160 - val_mse: 6428.4395\n",
      "Epoch 17/100\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 6228.5327 - mae: 77.3056 - mse: 6228.5327 - val_loss: 5971.0073 - val_mae: 75.6508 - val_mse: 5971.0073\n",
      "Epoch 18/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 5781.5640 - mae: 74.3604 - mse: 5781.5640 - val_loss: 5536.3223 - val_mae: 72.7211 - val_mse: 5536.3223\n",
      "Epoch 19/100\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 5356.4868 - mae: 71.4455 - mse: 5356.4868 - val_loss: 5122.9961 - val_mae: 69.8214 - val_mse: 5122.9961\n",
      "Epoch 20/100\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 4952.8472 - mae: 68.5576 - mse: 4952.8472 - val_loss: 4730.8618 - val_mae: 66.9544 - val_mse: 4730.8618\n",
      "Epoch 21/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 4569.8682 - mae: 65.7089 - mse: 4569.8682 - val_loss: 4359.0869 - val_mae: 64.1180 - val_mse: 4359.0869\n",
      "Epoch 22/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 4207.2012 - mae: 62.8898 - mse: 4207.2012 - val_loss: 4007.6514 - val_mae: 61.3162 - val_mse: 4007.6514\n",
      "Epoch 23/100\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 3864.4402 - mae: 60.1028 - mse: 3864.4402 - val_loss: 3675.6309 - val_mae: 58.5462 - val_mse: 3675.6309\n",
      "Epoch 24/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 3541.0461 - mae: 57.3472 - mse: 3541.0461 - val_loss: 3362.4700 - val_mae: 55.8077 - val_mse: 3362.4700\n",
      "Epoch 25/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 3236.4004 - mae: 54.6277 - mse: 3236.4004 - val_loss: 3068.2092 - val_mae: 53.1059 - val_mse: 3068.2092\n",
      "Epoch 26/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 2950.2644 - mae: 51.9422 - mse: 2950.2644 - val_loss: 2791.7825 - val_mae: 50.4362 - val_mse: 2791.7827\n",
      "Epoch 27/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 2682.3489 - mae: 49.2927 - mse: 2682.3489 - val_loss: 2534.0659 - val_mae: 47.8132 - val_mse: 2534.0659\n",
      "Epoch 28/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 2431.8857 - mae: 46.6872 - mse: 2431.8857 - val_loss: 2293.0044 - val_mae: 45.2221 - val_mse: 2293.0044\n",
      "Epoch 29/100\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 2198.5537 - mae: 44.1148 - mse: 2198.5537 - val_loss: 2069.0103 - val_mae: 42.6737 - val_mse: 2069.0103\n",
      "Epoch 30/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 1981.8097 - mae: 41.5900 - mse: 1981.8097 - val_loss: 1861.3311 - val_mae: 40.1667 - val_mse: 1861.3311\n",
      "Epoch 31/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 1781.2323 - mae: 39.1013 - mse: 1781.2323 - val_loss: 1669.5348 - val_mae: 37.7037 - val_mse: 1669.5348\n",
      "Epoch 32/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 1596.4553 - mae: 36.6670 - mse: 1596.4553 - val_loss: 1493.1783 - val_mae: 35.2875 - val_mse: 1493.1783\n",
      "Epoch 33/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 1426.7628 - mae: 34.2731 - mse: 1426.7627 - val_loss: 1331.6874 - val_mae: 32.9199 - val_mse: 1331.6874\n",
      "Epoch 34/100\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 1271.7146 - mae: 31.9418 - mse: 1271.7146 - val_loss: 1184.7345 - val_mae: 30.6108 - val_mse: 1184.7345\n",
      "Epoch 35/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 1130.8763 - mae: 29.6758 - mse: 1130.8763 - val_loss: 1051.7332 - val_mae: 28.4051 - val_mse: 1051.7332\n",
      "Epoch 36/100\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 1003.6124 - mae: 27.5058 - mse: 1003.6124 - val_loss: 931.7747 - val_mae: 26.2809 - val_mse: 931.7747\n",
      "Epoch 37/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 889.4497 - mae: 25.4174 - mse: 889.4497 - val_loss: 824.7500 - val_mae: 24.2929 - val_mse: 824.7500\n",
      "Epoch 38/100\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 787.7026 - mae: 23.5651 - mse: 787.7026 - val_loss: 729.5798 - val_mae: 22.6536 - val_mse: 729.5798\n",
      "Epoch 39/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 697.6851 - mae: 22.1300 - mse: 697.6851 - val_loss: 645.9197 - val_mae: 21.3777 - val_mse: 645.9197\n",
      "Epoch 40/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 618.7225 - mae: 20.8982 - mse: 618.7225 - val_loss: 572.9598 - val_mae: 20.2116 - val_mse: 572.9597\n",
      "Epoch 41/100\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 550.0386 - mae: 19.7505 - mse: 550.0386 - val_loss: 509.8386 - val_mae: 19.1230 - val_mse: 509.8387\n",
      "Epoch 42/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 490.9882 - mae: 18.6845 - mse: 490.9882 - val_loss: 456.0871 - val_mae: 18.1044 - val_mse: 456.0871\n",
      "Epoch 43/100\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 440.8734 - mae: 17.6876 - mse: 440.8734 - val_loss: 410.4847 - val_mae: 17.1490 - val_mse: 410.4847\n",
      "Epoch 44/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 398.9098 - mae: 16.7753 - mse: 398.9098 - val_loss: 372.9413 - val_mae: 16.2768 - val_mse: 372.9413\n",
      "Epoch 45/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 364.2336 - mae: 15.9435 - mse: 364.2336 - val_loss: 342.0671 - val_mae: 15.4751 - val_mse: 342.0671\n",
      "Epoch 46/100\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 336.1002 - mae: 15.1842 - mse: 336.1002 - val_loss: 317.5289 - val_mae: 14.7555 - val_mse: 317.5289\n",
      "Epoch 47/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 313.6323 - mae: 14.5009 - mse: 313.6323 - val_loss: 297.9336 - val_mae: 14.0979 - val_mse: 297.9336\n",
      "Epoch 48/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 296.1066 - mae: 13.8861 - mse: 296.1066 - val_loss: 283.0912 - val_mae: 13.5170 - val_mse: 283.0912\n",
      "Epoch 49/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 282.7112 - mae: 13.3403 - mse: 282.7112 - val_loss: 271.8540 - val_mae: 12.9971 - val_mse: 271.8540\n",
      "Epoch 50/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 272.7478 - mae: 12.8702 - mse: 272.7479 - val_loss: 263.6818 - val_mae: 12.5430 - val_mse: 263.6818\n",
      "Epoch 51/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 265.5424 - mae: 12.4538 - mse: 265.5424 - val_loss: 257.8870 - val_mae: 12.1495 - val_mse: 257.8870\n",
      "Epoch 52/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 260.5013 - mae: 12.0979 - mse: 260.5013 - val_loss: 253.9929 - val_mae: 11.8200 - val_mse: 253.9929\n",
      "Epoch 53/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 257.1068 - mae: 11.8064 - mse: 257.1068 - val_loss: 251.4583 - val_mae: 11.5483 - val_mse: 251.4583\n",
      "Epoch 54/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 254.8522 - mae: 11.5630 - mse: 254.8522 - val_loss: 249.8196 - val_mae: 11.3257 - val_mse: 249.8196\n",
      "Epoch 55/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 253.4681 - mae: 11.3786 - mse: 253.4681 - val_loss: 248.8883 - val_mae: 11.1831 - val_mse: 248.8883\n",
      "Epoch 56/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 252.6556 - mae: 11.2769 - mse: 252.6556 - val_loss: 248.4013 - val_mae: 11.0924 - val_mse: 248.4013\n",
      "Epoch 57/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 252.1863 - mae: 11.1979 - mse: 252.1863 - val_loss: 248.1370 - val_mae: 11.0361 - val_mse: 248.1370\n",
      "Epoch 58/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 251.9392 - mae: 11.1774 - mse: 251.9392 - val_loss: 248.0248 - val_mae: 11.0391 - val_mse: 248.0248\n",
      "Epoch 59/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 251.7890 - mae: 11.1950 - mse: 251.7890 - val_loss: 247.9752 - val_mae: 11.0565 - val_mse: 247.9752\n",
      "Epoch 60/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 178.0201 - mae: 8.4026 - mse: 178.0201 - val_loss: 117.7743 - val_mae: 5.9910 - val_mse: 117.7743\n",
      "Epoch 61/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 110.4849 - mae: 5.5681 - mse: 110.4849 - val_loss: 94.4503 - val_mae: 5.0090 - val_mse: 94.4503\n",
      "Epoch 62/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 89.2231 - mae: 4.8648 - mse: 89.2231 - val_loss: 76.2366 - val_mae: 4.4051 - val_mse: 76.2366\n",
      "Epoch 63/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 72.1491 - mae: 4.2962 - mse: 72.1491 - val_loss: 61.4342 - val_mae: 3.8911 - val_mse: 61.4342\n",
      "Epoch 64/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 58.3727 - mae: 3.8257 - mse: 58.3727 - val_loss: 49.5777 - val_mae: 3.4499 - val_mse: 49.5777\n",
      "Epoch 65/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 47.1245 - mae: 3.3723 - mse: 47.1245 - val_loss: 39.9146 - val_mae: 3.0631 - val_mse: 39.9146\n",
      "Epoch 66/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 38.0395 - mae: 2.9863 - mse: 38.0395 - val_loss: 32.1950 - val_mae: 2.6962 - val_mse: 32.1950\n",
      "Epoch 67/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 30.6899 - mae: 2.6406 - mse: 30.6899 - val_loss: 25.9624 - val_mae: 2.4013 - val_mse: 25.9624\n",
      "Epoch 68/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 24.7820 - mae: 2.3530 - mse: 24.7820 - val_loss: 20.8863 - val_mae: 2.1352 - val_mse: 20.8863\n",
      "Epoch 69/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 20.0486 - mae: 2.0997 - mse: 20.0486 - val_loss: 16.9277 - val_mae: 1.9163 - val_mse: 16.9277\n",
      "Epoch 70/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 16.2585 - mae: 1.8884 - mse: 16.2585 - val_loss: 13.7485 - val_mae: 1.7421 - val_mse: 13.7485\n",
      "Epoch 71/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 13.2011 - mae: 1.7069 - mse: 13.2011 - val_loss: 11.1015 - val_mae: 1.5553 - val_mse: 11.1015\n",
      "Epoch 72/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 10.7360 - mae: 1.5454 - mse: 10.7360 - val_loss: 8.9926 - val_mae: 1.3969 - val_mse: 8.9926\n",
      "Epoch 73/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 8.7116 - mae: 1.3911 - mse: 8.7116 - val_loss: 7.3102 - val_mae: 1.2717 - val_mse: 7.3102\n",
      "Epoch 74/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 7.0993 - mae: 1.2639 - mse: 7.0993 - val_loss: 5.9527 - val_mae: 1.1539 - val_mse: 5.9527\n",
      "Epoch 75/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 5.8332 - mae: 1.1638 - mse: 5.8332 - val_loss: 4.8703 - val_mae: 1.0561 - val_mse: 4.8703\n",
      "Epoch 76/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 4.8054 - mae: 1.0692 - mse: 4.8054 - val_loss: 4.0194 - val_mae: 0.9704 - val_mse: 4.0194\n",
      "Epoch 77/100\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 3.9451 - mae: 0.9680 - mse: 3.9451 - val_loss: 3.3399 - val_mae: 0.8955 - val_mse: 3.3399\n",
      "Epoch 78/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 3.2928 - mae: 0.9070 - mse: 3.2928 - val_loss: 2.7866 - val_mae: 0.8347 - val_mse: 2.7866\n",
      "Epoch 79/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 2.7507 - mae: 0.8383 - mse: 2.7507 - val_loss: 2.3961 - val_mae: 0.7918 - val_mse: 2.3961\n",
      "Epoch 80/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 2.3434 - mae: 0.7886 - mse: 2.3434 - val_loss: 2.0184 - val_mae: 0.7408 - val_mse: 2.0184\n",
      "Epoch 81/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 2.0008 - mae: 0.7457 - mse: 2.0008 - val_loss: 1.7365 - val_mae: 0.6878 - val_mse: 1.7365\n",
      "Epoch 82/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 1.7373 - mae: 0.7098 - mse: 1.7373 - val_loss: 1.5632 - val_mae: 0.6865 - val_mse: 1.5632\n",
      "Epoch 83/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 1.5344 - mae: 0.6849 - mse: 1.5344 - val_loss: 1.3710 - val_mae: 0.6605 - val_mse: 1.3710\n",
      "Epoch 84/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 1.3446 - mae: 0.6542 - mse: 1.3446 - val_loss: 1.2151 - val_mae: 0.6264 - val_mse: 1.2151\n",
      "Epoch 85/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 1.1921 - mae: 0.6265 - mse: 1.1921 - val_loss: 1.1010 - val_mae: 0.6105 - val_mse: 1.1010\n",
      "Epoch 86/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 1.0743 - mae: 0.6037 - mse: 1.0743 - val_loss: 0.9958 - val_mae: 0.5873 - val_mse: 0.9958\n",
      "Epoch 87/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.9727 - mae: 0.5869 - mse: 0.9727 - val_loss: 0.9095 - val_mae: 0.5807 - val_mse: 0.9095\n",
      "Epoch 88/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.8836 - mae: 0.5686 - mse: 0.8836 - val_loss: 0.8318 - val_mae: 0.5580 - val_mse: 0.8318\n",
      "Epoch 89/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.8416 - mae: 0.5704 - mse: 0.8416 - val_loss: 0.7954 - val_mae: 0.5599 - val_mse: 0.7954\n",
      "Epoch 90/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 0.7658 - mae: 0.5473 - mse: 0.7658 - val_loss: 0.7808 - val_mae: 0.5907 - val_mse: 0.7808\n",
      "Epoch 91/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 0.7346 - mae: 0.5468 - mse: 0.7346 - val_loss: 0.7173 - val_mae: 0.5469 - val_mse: 0.7173\n",
      "Epoch 92/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6860 - mae: 0.5383 - mse: 0.6860 - val_loss: 0.6814 - val_mae: 0.5468 - val_mse: 0.6814\n",
      "Epoch 93/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 0.6523 - mae: 0.5269 - mse: 0.6523 - val_loss: 0.6332 - val_mae: 0.5200 - val_mse: 0.6332\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 0s 2ms/step - loss: 0.6289 - mae: 0.5249 - mse: 0.6289 - val_loss: 0.5809 - val_mae: 0.5038 - val_mse: 0.5809\n",
      "Epoch 95/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 0.5962 - mae: 0.5146 - mse: 0.5962 - val_loss: 0.6791 - val_mae: 0.5545 - val_mse: 0.6791\n",
      "Epoch 96/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 0.5758 - mae: 0.5118 - mse: 0.5758 - val_loss: 0.5602 - val_mae: 0.5047 - val_mse: 0.5602\n",
      "Epoch 97/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 0.5525 - mae: 0.5008 - mse: 0.5525 - val_loss: 0.5354 - val_mae: 0.4994 - val_mse: 0.5354\n",
      "Epoch 98/100\n",
      "169/169 [==============================] - 0s 3ms/step - loss: 0.5380 - mae: 0.4979 - mse: 0.5380 - val_loss: 0.5667 - val_mae: 0.5349 - val_mse: 0.5667\n",
      "Epoch 99/100\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.5210 - mae: 0.4941 - mse: 0.5210 - val_loss: 0.5135 - val_mae: 0.4969 - val_mse: 0.5135\n",
      "Epoch 100/100\n",
      "169/169 [==============================] - 0s 2ms/step - loss: 0.5100 - mae: 0.4911 - mse: 0.5100 - val_loss: 0.5429 - val_mae: 0.5057 - val_mse: 0.5429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b0c712100>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add( Dense( units = 50 , activation = 'relu' , kernel_initializer = 'normal', input_dim = 7)) \n",
    "model.add( Dense( units = 20 , activation = 'tanh' , kernel_initializer = 'normal' )) \n",
    "model.add( Dense( units = 1  , kernel_initializer = 'normal' )) \n",
    "\n",
    "model.compile(optimizer= \"adam\", loss=\"mse\", metrics= [\"mae\", \"mse\"])\n",
    "model.fit(x_train_scaled, y_train , batch_size=50, validation_split=0.3, epochs=100,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0373c868",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step\n",
      "batch_size: 5 - epochs: 5 Accuracy: TEY    97.586453\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "batch_size: 5 - epochs: 10 Accuracy: TEY    99.446121\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "batch_size: 5 - epochs: 50 Accuracy: TEY    99.625289\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "batch_size: 5 - epochs: 100 Accuracy: TEY    99.66114\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "batch_size: 10 - epochs: 5 Accuracy: TEY    81.125813\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "batch_size: 10 - epochs: 10 Accuracy: TEY    98.259452\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "batch_size: 10 - epochs: 50 Accuracy: TEY    99.612469\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "batch_size: 10 - epochs: 100 Accuracy: TEY    99.648396\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "batch_size: 15 - epochs: 5 Accuracy: TEY    58.631911\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "batch_size: 15 - epochs: 10 Accuracy: TEY    89.837377\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "batch_size: 15 - epochs: 50 Accuracy: TEY    99.64709\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "batch_size: 15 - epochs: 100 Accuracy: TEY    99.640519\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "batch_size: 20 - epochs: 5 Accuracy: TEY    46.031848\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "batch_size: 20 - epochs: 10 Accuracy: TEY    81.069346\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "batch_size: 20 - epochs: 50 Accuracy: TEY    99.56673\n",
      "dtype: float64\n",
      "94/94 [==============================] - 0s 995us/step\n",
      "batch_size: 20 - epochs: 100 Accuracy: TEY    99.612713\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batchsize</th>\n",
       "      <th>epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>TEY    97.586453\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>TEY    99.446121\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>TEY    99.625289\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>TEY    99.66114\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>TEY    81.125813\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>TEY    98.259452\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>TEY    99.612469\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>TEY    99.648396\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>TEY    58.631911\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>TEY    89.837377\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>TEY    99.64709\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>TEY    99.640519\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>TEY    46.031848\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>TEY    81.069346\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>TEY    99.56673\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>TEY    99.612713\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batchsize  epochs                         Accuracy\n",
       "0          5       5  TEY    97.586453\n",
       "dtype: float64\n",
       "0          5      10  TEY    99.446121\n",
       "dtype: float64\n",
       "0          5      50  TEY    99.625289\n",
       "dtype: float64\n",
       "0          5     100   TEY    99.66114\n",
       "dtype: float64\n",
       "0         10       5  TEY    81.125813\n",
       "dtype: float64\n",
       "0         10      10  TEY    98.259452\n",
       "dtype: float64\n",
       "0         10      50  TEY    99.612469\n",
       "dtype: float64\n",
       "0         10     100  TEY    99.648396\n",
       "dtype: float64\n",
       "0         15       5  TEY    58.631911\n",
       "dtype: float64\n",
       "0         15      10  TEY    89.837377\n",
       "dtype: float64\n",
       "0         15      50   TEY    99.64709\n",
       "dtype: float64\n",
       "0         15     100  TEY    99.640519\n",
       "dtype: float64\n",
       "0         20       5  TEY    46.031848\n",
       "dtype: float64\n",
       "0         20      10  TEY    81.069346\n",
       "dtype: float64\n",
       "0         20      50   TEY    99.56673\n",
       "dtype: float64\n",
       "0         20     100  TEY    99.612713\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toFindBestParams(x_train_scaled, y_train, x_test_scaled, y_test):\n",
    "        \n",
    "    \n",
    "    batch_size_list = [5 , 10 , 15 , 20]\n",
    "    epoch_list      = [5 , 10 , 50 , 100]\n",
    "     \n",
    "    bestParamTable = pd.DataFrame()\n",
    "    \n",
    "    for batch_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "            \n",
    "            \n",
    "            model = Sequential()\n",
    "            \n",
    "            model.add(Dense(units=50, input_dim=x_train_scaled.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "            \n",
    "            \n",
    "            model.add(Dense(units=20, kernel_initializer='normal', activation='tanh'))\n",
    " \n",
    "        \n",
    "            model.add(Dense(1, kernel_initializer='normal'))\n",
    " \n",
    "            \n",
    "            model.compile(optimizer ='adam', loss = 'mean_squared_error')\n",
    "            \n",
    "           \n",
    "            model.fit(x_train_scaled, y_train , batch_size=batch_trial, epochs=epochs_trial,  verbose=0)\n",
    "                        \n",
    "            MAPE = np.mean(100 * (np.abs(y_test-model.predict(x_test_scaled))/y_test))  \n",
    "                        \n",
    "            bestParamTable=bestParamTable.append(pd.DataFrame(data=[[batch_trial, epochs_trial, 100-MAPE]],\n",
    "                                                        columns=['batchsize','epochs','Accuracy'] ))\n",
    "            \n",
    "            \n",
    "            print('batch_size:', batch_trial,'-', 'epochs:',epochs_trial, 'Accuracy:',100-MAPE)\n",
    "\n",
    "    return bestParamTable\n",
    "\n",
    "\n",
    "finalParamTable = toFindBestParams(x_train_scaled, y_train, x_test_scaled, y_test)\n",
    "finalParamTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7710975f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>TEY    97.586453\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>TEY    99.446121\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>TEY    99.625289\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>TEY    99.66114\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>TEY    81.125813\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>TEY    98.259452\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>TEY    99.612469\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>TEY    99.648396\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>TEY    58.631911\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>TEY    89.837377\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>TEY    99.64709\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>TEY    99.640519\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>TEY    46.031848\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>TEY    81.069346\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>TEY    99.56673\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>TEY    99.612713\n",
       "dtype: float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  batchsize  epochs                         Accuracy\n",
       "0       0          5       5  TEY    97.586453\n",
       "dtype: float64\n",
       "1       0          5      10  TEY    99.446121\n",
       "dtype: float64\n",
       "2       0          5      50  TEY    99.625289\n",
       "dtype: float64\n",
       "3       0          5     100   TEY    99.66114\n",
       "dtype: float64\n",
       "4       0         10       5  TEY    81.125813\n",
       "dtype: float64\n",
       "5       0         10      10  TEY    98.259452\n",
       "dtype: float64\n",
       "6       0         10      50  TEY    99.612469\n",
       "dtype: float64\n",
       "7       0         10     100  TEY    99.648396\n",
       "dtype: float64\n",
       "8       0         15       5  TEY    58.631911\n",
       "dtype: float64\n",
       "9       0         15      10  TEY    89.837377\n",
       "dtype: float64\n",
       "10      0         15      50   TEY    99.64709\n",
       "dtype: float64\n",
       "11      0         15     100  TEY    99.640519\n",
       "dtype: float64\n",
       "12      0         20       5  TEY    46.031848\n",
       "dtype: float64\n",
       "13      0         20      10  TEY    81.069346\n",
       "dtype: float64\n",
       "14      0         20      50   TEY    99.56673\n",
       "dtype: float64\n",
       "15      0         20     100  TEY    99.612713\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalParamTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fe1c959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b0eed7310>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer ='adam', loss = 'mean_squared_error')\n",
    "\n",
    "model.fit(x_train_scaled,y_train, batch_size=20 , epochs = 100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2eff269c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step\n",
      "(3008, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>AT</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13312</th>\n",
       "      <td>12.219</td>\n",
       "      <td>25.762</td>\n",
       "      <td>1092.5</td>\n",
       "      <td>550.25</td>\n",
       "      <td>4.0023</td>\n",
       "      <td>1.26430</td>\n",
       "      <td>24.0930</td>\n",
       "      <td>134.46</td>\n",
       "      <td>134.633133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12627</th>\n",
       "      <td>10.791</td>\n",
       "      <td>20.085</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.94</td>\n",
       "      <td>3.2106</td>\n",
       "      <td>2.69370</td>\n",
       "      <td>20.4500</td>\n",
       "      <td>111.88</td>\n",
       "      <td>112.646744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>12.126</td>\n",
       "      <td>25.221</td>\n",
       "      <td>1089.9</td>\n",
       "      <td>549.62</td>\n",
       "      <td>4.5325</td>\n",
       "      <td>1.96250</td>\n",
       "      <td>20.2620</td>\n",
       "      <td>133.72</td>\n",
       "      <td>134.133118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>12.218</td>\n",
       "      <td>25.965</td>\n",
       "      <td>1092.9</td>\n",
       "      <td>549.96</td>\n",
       "      <td>4.4266</td>\n",
       "      <td>1.57120</td>\n",
       "      <td>26.8620</td>\n",
       "      <td>133.79</td>\n",
       "      <td>133.998703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12462</th>\n",
       "      <td>10.466</td>\n",
       "      <td>19.688</td>\n",
       "      <td>1056.9</td>\n",
       "      <td>550.01</td>\n",
       "      <td>3.1241</td>\n",
       "      <td>2.29960</td>\n",
       "      <td>19.4090</td>\n",
       "      <td>110.77</td>\n",
       "      <td>111.242401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7405</th>\n",
       "      <td>10.624</td>\n",
       "      <td>19.387</td>\n",
       "      <td>1058.9</td>\n",
       "      <td>550.17</td>\n",
       "      <td>3.3709</td>\n",
       "      <td>4.27640</td>\n",
       "      <td>2.2158</td>\n",
       "      <td>113.32</td>\n",
       "      <td>113.595749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10993</th>\n",
       "      <td>12.088</td>\n",
       "      <td>25.392</td>\n",
       "      <td>1089.7</td>\n",
       "      <td>550.11</td>\n",
       "      <td>3.7871</td>\n",
       "      <td>0.83578</td>\n",
       "      <td>23.8520</td>\n",
       "      <td>133.77</td>\n",
       "      <td>133.722794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488</th>\n",
       "      <td>11.498</td>\n",
       "      <td>23.225</td>\n",
       "      <td>1079.4</td>\n",
       "      <td>549.60</td>\n",
       "      <td>4.2837</td>\n",
       "      <td>2.01980</td>\n",
       "      <td>12.3950</td>\n",
       "      <td>128.98</td>\n",
       "      <td>128.990356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14201</th>\n",
       "      <td>13.971</td>\n",
       "      <td>32.518</td>\n",
       "      <td>1100.1</td>\n",
       "      <td>528.98</td>\n",
       "      <td>5.1559</td>\n",
       "      <td>0.87760</td>\n",
       "      <td>12.3590</td>\n",
       "      <td>159.42</td>\n",
       "      <td>160.641251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>13.862</td>\n",
       "      <td>32.105</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>530.69</td>\n",
       "      <td>5.9309</td>\n",
       "      <td>10.75000</td>\n",
       "      <td>8.6376</td>\n",
       "      <td>161.86</td>\n",
       "      <td>159.691696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CDP    GTEP     TIT     TAT    AFDP        CO       AT  Actual  \\\n",
       "13312  12.219  25.762  1092.5  550.25  4.0023   1.26430  24.0930  134.46   \n",
       "12627  10.791  20.085  1059.6  549.94  3.2106   2.69370  20.4500  111.88   \n",
       "6393   12.126  25.221  1089.9  549.62  4.5325   1.96250  20.2620  133.72   \n",
       "4990   12.218  25.965  1092.9  549.96  4.4266   1.57120  26.8620  133.79   \n",
       "12462  10.466  19.688  1056.9  550.01  3.1241   2.29960  19.4090  110.77   \n",
       "7405   10.624  19.387  1058.9  550.17  3.3709   4.27640   2.2158  113.32   \n",
       "10993  12.088  25.392  1089.7  550.11  3.7871   0.83578  23.8520  133.77   \n",
       "9488   11.498  23.225  1079.4  549.60  4.2837   2.01980  12.3950  128.98   \n",
       "14201  13.971  32.518  1100.1  528.98  5.1559   0.87760  12.3590  159.42   \n",
       "9757   13.862  32.105  1100.0  530.69  5.9309  10.75000   8.6376  161.86   \n",
       "\n",
       "        Predicted  \n",
       "13312  134.633133  \n",
       "12627  112.646744  \n",
       "6393   134.133118  \n",
       "4990   133.998703  \n",
       "12462  111.242401  \n",
       "7405   113.595749  \n",
       "10993  133.722794  \n",
       "9488   128.990356  \n",
       "14201  160.641251  \n",
       "9757   159.691696  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_test = model.predict(x_test_scaled) \n",
    "\n",
    "\n",
    "predictions_df = pd.DataFrame(x_test)\n",
    "predictions_df['Actual'] = y_test\n",
    "predictions_df['Predicted'] = y_predict_test\n",
    "print(predictions_df.shape)\n",
    "predictions_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cd0920e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step\n",
      "(3008, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>AT</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13312</th>\n",
       "      <td>12.219</td>\n",
       "      <td>25.762</td>\n",
       "      <td>1092.5</td>\n",
       "      <td>550.25</td>\n",
       "      <td>4.0023</td>\n",
       "      <td>1.26430</td>\n",
       "      <td>24.0930</td>\n",
       "      <td>134.46</td>\n",
       "      <td>134.633133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12627</th>\n",
       "      <td>10.791</td>\n",
       "      <td>20.085</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.94</td>\n",
       "      <td>3.2106</td>\n",
       "      <td>2.69370</td>\n",
       "      <td>20.4500</td>\n",
       "      <td>111.88</td>\n",
       "      <td>112.646744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>12.126</td>\n",
       "      <td>25.221</td>\n",
       "      <td>1089.9</td>\n",
       "      <td>549.62</td>\n",
       "      <td>4.5325</td>\n",
       "      <td>1.96250</td>\n",
       "      <td>20.2620</td>\n",
       "      <td>133.72</td>\n",
       "      <td>134.133118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>12.218</td>\n",
       "      <td>25.965</td>\n",
       "      <td>1092.9</td>\n",
       "      <td>549.96</td>\n",
       "      <td>4.4266</td>\n",
       "      <td>1.57120</td>\n",
       "      <td>26.8620</td>\n",
       "      <td>133.79</td>\n",
       "      <td>133.998703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12462</th>\n",
       "      <td>10.466</td>\n",
       "      <td>19.688</td>\n",
       "      <td>1056.9</td>\n",
       "      <td>550.01</td>\n",
       "      <td>3.1241</td>\n",
       "      <td>2.29960</td>\n",
       "      <td>19.4090</td>\n",
       "      <td>110.77</td>\n",
       "      <td>111.242401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7405</th>\n",
       "      <td>10.624</td>\n",
       "      <td>19.387</td>\n",
       "      <td>1058.9</td>\n",
       "      <td>550.17</td>\n",
       "      <td>3.3709</td>\n",
       "      <td>4.27640</td>\n",
       "      <td>2.2158</td>\n",
       "      <td>113.32</td>\n",
       "      <td>113.595749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10993</th>\n",
       "      <td>12.088</td>\n",
       "      <td>25.392</td>\n",
       "      <td>1089.7</td>\n",
       "      <td>550.11</td>\n",
       "      <td>3.7871</td>\n",
       "      <td>0.83578</td>\n",
       "      <td>23.8520</td>\n",
       "      <td>133.77</td>\n",
       "      <td>133.722794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488</th>\n",
       "      <td>11.498</td>\n",
       "      <td>23.225</td>\n",
       "      <td>1079.4</td>\n",
       "      <td>549.60</td>\n",
       "      <td>4.2837</td>\n",
       "      <td>2.01980</td>\n",
       "      <td>12.3950</td>\n",
       "      <td>128.98</td>\n",
       "      <td>128.990356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14201</th>\n",
       "      <td>13.971</td>\n",
       "      <td>32.518</td>\n",
       "      <td>1100.1</td>\n",
       "      <td>528.98</td>\n",
       "      <td>5.1559</td>\n",
       "      <td>0.87760</td>\n",
       "      <td>12.3590</td>\n",
       "      <td>159.42</td>\n",
       "      <td>160.641251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>13.862</td>\n",
       "      <td>32.105</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>530.69</td>\n",
       "      <td>5.9309</td>\n",
       "      <td>10.75000</td>\n",
       "      <td>8.6376</td>\n",
       "      <td>161.86</td>\n",
       "      <td>159.691696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CDP    GTEP     TIT     TAT    AFDP        CO       AT  Actual  \\\n",
       "13312  12.219  25.762  1092.5  550.25  4.0023   1.26430  24.0930  134.46   \n",
       "12627  10.791  20.085  1059.6  549.94  3.2106   2.69370  20.4500  111.88   \n",
       "6393   12.126  25.221  1089.9  549.62  4.5325   1.96250  20.2620  133.72   \n",
       "4990   12.218  25.965  1092.9  549.96  4.4266   1.57120  26.8620  133.79   \n",
       "12462  10.466  19.688  1056.9  550.01  3.1241   2.29960  19.4090  110.77   \n",
       "7405   10.624  19.387  1058.9  550.17  3.3709   4.27640   2.2158  113.32   \n",
       "10993  12.088  25.392  1089.7  550.11  3.7871   0.83578  23.8520  133.77   \n",
       "9488   11.498  23.225  1079.4  549.60  4.2837   2.01980  12.3950  128.98   \n",
       "14201  13.971  32.518  1100.1  528.98  5.1559   0.87760  12.3590  159.42   \n",
       "9757   13.862  32.105  1100.0  530.69  5.9309  10.75000   8.6376  161.86   \n",
       "\n",
       "        Predicted  \n",
       "13312  134.633133  \n",
       "12627  112.646744  \n",
       "6393   134.133118  \n",
       "4990   133.998703  \n",
       "12462  111.242401  \n",
       "7405   113.595749  \n",
       "10993  133.722794  \n",
       "9488   128.990356  \n",
       "14201  160.641251  \n",
       "9757   159.691696  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_test = model.predict(x_test_scaled) \n",
    "\n",
    "\n",
    "predictions_df = pd.DataFrame(x_test)\n",
    "predictions_df['Actual'] = y_test\n",
    "predictions_df['Predicted'] = y_predict_test\n",
    "print(predictions_df.shape)\n",
    "predictions_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f913b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.drop(['CDP','GTEP','TIT','TAT','AFDP','CO','AT'], axis =1 , inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "481fd2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Test Data -- ANN model =  99.64174824957966\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>APE %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13312</th>\n",
       "      <td>134.46</td>\n",
       "      <td>134.633133</td>\n",
       "      <td>0.128762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12627</th>\n",
       "      <td>111.88</td>\n",
       "      <td>112.646744</td>\n",
       "      <td>0.685327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>133.72</td>\n",
       "      <td>134.133118</td>\n",
       "      <td>0.308942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>133.79</td>\n",
       "      <td>133.998703</td>\n",
       "      <td>0.155993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12462</th>\n",
       "      <td>110.77</td>\n",
       "      <td>111.242401</td>\n",
       "      <td>0.426470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual   Predicted     APE %\n",
       "13312  134.46  134.633133  0.128762\n",
       "12627  111.88  112.646744  0.685327\n",
       "6393   133.72  134.133118  0.308942\n",
       "4990   133.79  133.998703  0.155993\n",
       "12462  110.77  111.242401  0.426470"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\n",
    "APE=100*(abs(predictions_df['Actual']-predictions_df['Predicted'])/predictions_df['Actual'])\n",
    "print('The Accuracy for Test Data -- ANN model = ', 100-np.mean(APE))\n",
    "\n",
    "\n",
    "predictions_df['APE %']=APE\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "efe4d125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>APE %</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134.46</td>\n",
       "      <td>134.633133</td>\n",
       "      <td>0.128762</td>\n",
       "      <td>-0.001288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111.88</td>\n",
       "      <td>112.646744</td>\n",
       "      <td>0.685327</td>\n",
       "      <td>-0.006853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.72</td>\n",
       "      <td>134.133118</td>\n",
       "      <td>0.308942</td>\n",
       "      <td>-0.003089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133.79</td>\n",
       "      <td>133.998703</td>\n",
       "      <td>0.155993</td>\n",
       "      <td>-0.001560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110.77</td>\n",
       "      <td>111.242401</td>\n",
       "      <td>0.426470</td>\n",
       "      <td>-0.004265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>119.25</td>\n",
       "      <td>119.820793</td>\n",
       "      <td>0.478653</td>\n",
       "      <td>-0.004787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>133.74</td>\n",
       "      <td>134.101135</td>\n",
       "      <td>0.270028</td>\n",
       "      <td>-0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>146.31</td>\n",
       "      <td>147.333267</td>\n",
       "      <td>0.699383</td>\n",
       "      <td>-0.006994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>150.07</td>\n",
       "      <td>150.287277</td>\n",
       "      <td>0.144784</td>\n",
       "      <td>-0.001448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>111.77</td>\n",
       "      <td>111.917999</td>\n",
       "      <td>0.132414</td>\n",
       "      <td>-0.001324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3008 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual   Predicted     APE %     Error\n",
       "0     134.46  134.633133  0.128762 -0.001288\n",
       "1     111.88  112.646744  0.685327 -0.006853\n",
       "2     133.72  134.133118  0.308942 -0.003089\n",
       "3     133.79  133.998703  0.155993 -0.001560\n",
       "4     110.77  111.242401  0.426470 -0.004265\n",
       "...      ...         ...       ...       ...\n",
       "3003  119.25  119.820793  0.478653 -0.004787\n",
       "3004  133.74  134.101135  0.270028 -0.002700\n",
       "3005  146.31  147.333267  0.699383 -0.006994\n",
       "3006  150.07  150.287277  0.144784 -0.001448\n",
       "3007  111.77  111.917999  0.132414 -0.001324\n",
       "\n",
       "[3008 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df['Error'] = (predictions_df['Actual'] - predictions_df['Predicted'])/(predictions_df['Actual'])\n",
    "predictions_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "651ebaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x21b0f2e84f0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted values\")\n",
    "plt.title(\"The Scatterplot of Relationship between Actual Values and Predictions\")\n",
    "plt.scatter(predictions_df['Actual'], predictions_df['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25d7540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.48120854966183946\n",
      "MSE: 0.4581731044635205\n",
      "RMSE: 0.6768848531792689\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"MAE:\",metrics.mean_absolute_error(y_test,y_predict_test))\n",
    "print (\"MSE:\",metrics.mean_squared_error(y_test,y_predict_test))\n",
    "print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test,y_predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11da05b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step\n",
      "376/376 [==============================] - 1s 2ms/step\n",
      "R2_score (train):  0.9986566562968023\n",
      "R2_score (test):  0.9981701593355503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_predict_test = model.predict(x_test_scaled)\n",
    "y_predict_train = model.predict(x_train_scaled) \n",
    "print('R2_score (train): ',r2_score(y_train, y_predict_train))\n",
    "print('R2_score (test): ',r2_score(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3f104e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99.85'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(np.round(metrics.explained_variance_score(y_test,y_predict_test)*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80000999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
